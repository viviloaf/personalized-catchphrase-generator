{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                Version\n",
      "---------------------- ----------\n",
      "absl-py                0.11.0\n",
      "aitextgen              0.2.3\n",
      "argon2-cffi            20.1.0\n",
      "async-generator        1.10\n",
      "attrs                  20.2.0\n",
      "backcall               0.2.0\n",
      "bleach                 3.2.1\n",
      "blis                   0.4.1\n",
      "cachetools             4.1.1\n",
      "catalogue              1.0.0\n",
      "certifi                2020.6.20\n",
      "cffi                   1.14.3\n",
      "chardet                3.0.4\n",
      "click                  7.1.2\n",
      "cymem                  2.0.4\n",
      "dataclasses            0.6\n",
      "decorator              4.4.2\n",
      "defusedxml             0.6.0\n",
      "en-core-web-sm         2.3.1\n",
      "entrypoints            0.3\n",
      "filelock               3.0.12\n",
      "fire                   0.3.1\n",
      "future                 0.18.2\n",
      "google-auth            1.23.0\n",
      "google-auth-oauthlib   0.4.2\n",
      "grpcio                 1.33.2\n",
      "idna                   2.10\n",
      "ipykernel              5.3.4\n",
      "ipython                7.19.0\n",
      "ipython-genutils       0.2.0\n",
      "ipywidgets             7.5.1\n",
      "jedi                   0.17.2\n",
      "Jinja2                 2.11.2\n",
      "joblib                 0.17.0\n",
      "jsonschema             3.2.0\n",
      "jupyter-client         6.1.7\n",
      "jupyter-core           4.6.3\n",
      "jupyterlab-pygments    0.1.2\n",
      "Markdown               3.3.3\n",
      "MarkupSafe             1.1.1\n",
      "mistune                0.8.4\n",
      "murmurhash             1.0.4\n",
      "nbclient               0.5.1\n",
      "nbconvert              6.0.7\n",
      "nbformat               5.0.8\n",
      "nest-asyncio           1.4.2\n",
      "notebook               6.1.4\n",
      "numpy                  1.19.4\n",
      "oauthlib               3.1.0\n",
      "packaging              20.4\n",
      "pandas                 1.1.4\n",
      "pandocfilters          1.4.3\n",
      "parso                  0.7.1\n",
      "pexpect                4.8.0\n",
      "pickleshare            0.7.5\n",
      "pip                    20.2.4\n",
      "plac                   1.1.3\n",
      "preshed                3.0.3\n",
      "prometheus-client      0.8.0\n",
      "prompt-toolkit         3.0.8\n",
      "protobuf               3.13.0\n",
      "ptyprocess             0.6.0\n",
      "pyasn1                 0.4.8\n",
      "pyasn1-modules         0.2.8\n",
      "pycparser              2.20\n",
      "Pygments               2.7.2\n",
      "pyparsing              2.4.7\n",
      "pyrsistent             0.17.3\n",
      "python-dateutil        2.8.1\n",
      "pytorch-lightning      0.7.6\n",
      "pytz                   2020.4\n",
      "PyYAML                 5.3.1\n",
      "pyzmq                  19.0.2\n",
      "regex                  2020.10.28\n",
      "requests               2.24.0\n",
      "requests-oauthlib      1.3.0\n",
      "rsa                    4.6\n",
      "sacremoses             0.0.43\n",
      "Send2Trash             1.5.0\n",
      "sentencepiece          0.1.94\n",
      "setuptools             41.2.0\n",
      "six                    1.15.0\n",
      "spacy                  2.3.2\n",
      "srsly                  1.0.2\n",
      "tensorboard            2.3.0\n",
      "tensorboard-plugin-wit 1.7.0\n",
      "termcolor              1.1.0\n",
      "terminado              0.9.1\n",
      "testpath               0.4.4\n",
      "thinc                  7.4.1\n",
      "tokenizers             0.7.0\n",
      "torch                  1.7.0\n",
      "torchtext              0.8.0\n",
      "tornado                6.1\n",
      "tqdm                   4.51.0\n",
      "traitlets              5.0.5\n",
      "transformers           2.9.1\n",
      "typing-extensions      3.7.4.3\n",
      "urllib3                1.25.11\n",
      "wasabi                 0.8.0\n",
      "wcwidth                0.2.5\n",
      "webencodings           0.5.1\n",
      "Werkzeug               1.0.1\n",
      "wheel                  0.35.1\n",
      "widgetsnbextension     3.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/04/2020 14:23:38 — INFO — transformers.file_utils — PyTorch version 1.7.0 available.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(\n",
    "        format=\"%(asctime)s — %(levelname)s — %(name)s — %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        level=logging.INFO\n",
    "    )\n",
    "\n",
    "from aitextgen import aitextgen\n",
    "from aitextgen.tokenizers import train_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Nov  3 22:18:41 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX TIT...  Off  | 00000000:08:00.0  On |                  N/A |\n",
      "| 22%   49C    P8    25W / 250W |    816MiB / 12207MiB |     11%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1419      G   /usr/lib/xorg/Xorg                257MiB |\n",
      "|    0   N/A  N/A      1717      G   /usr/bin/gnome-shell              110MiB |\n",
      "|    0   N/A  N/A      2108      G   ...AAAAAAAAA= --shared-files       19MiB |\n",
      "|    0   N/A  N/A      2607      G   ...AAAAAAAAA= --shared-files      422MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/03/2020 22:18:42 — INFO — aitextgen — Loading 124M GPT-2 model from /aitextgen.\n",
      "11/03/2020 22:18:45 — INFO — aitextgen — Using the default GPT-2 Tokenizer.\n"
     ]
    }
   ],
   "source": [
    "ai = aitextgen(tf_gpt2=\"124M\", to_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"../nguyen_vivian_sept_2009_oct_2020.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df['content'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = list(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('my_fb_text.txt', 'w') as filehandle:\n",
    "    for i in df:\n",
    "        filehandle.write('%s\\n' % i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'my_fb_text.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is currently a weird workflow where I need to save the data to a text file before loading\n",
    "# Maybe I can create a preprocessing class which handles this for me and outputs it into a text folder for batching\n",
    "# However, this kind of transfer learning is unsupervised learning and there is no sense of accuracy other than directly interacting with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d533ea7521843a694fe9ce6f8e64dee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, layout=Layout(flex='2'), max=43578.0), HTML(value=''))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/04/2020 09:41:17 — INFO — aitextgen.TokenDataset — Encoding 43,578 sets of tokens from my_fb_text.txt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/04/2020 09:41:19 — WARNING — aitextgen — pytorch_model.bin already exists in /trained_model and will be overwritten!\n",
      "GPU available: True, used: True\n",
      "11/04/2020 09:41:19 — INFO — lightning — GPU available: True, used: True\n",
      "No environment variable for node rank defined. Set as 0.\n",
      "11/04/2020 09:41:19 — WARNING — lightning — No environment variable for node rank defined. Set as 0.\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "11/04/2020 09:41:19 — INFO — lightning — CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38ba179087954b0ca7ef418a7d1c350a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, layout=Layout(flex='2'), max=5000.0), HTML(value='')),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m1,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "\n",
      "\n",
      "==========\n",
      "\u001b[1m2,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m2,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "\n",
      "\n",
      "==========\n",
      "\u001b[1m3,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m3,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "\n",
      "\n",
      "==========\n",
      "\u001b[1m4,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m4,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "\n",
      "\n",
      "==========\n",
      "\u001b[1m5,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m5,000 steps reached: generating sample texts.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/04/2020 10:17:52 — INFO — aitextgen — Saving trained model pytorch_model.bin to /trained_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "ð¥ºðð\n",
      "\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "ai.train(file_name,\n",
    "         line_by_line=True,\n",
    "         from_cache=False,\n",
    "         num_steps=5000,\n",
    "         generate_every=1000,\n",
    "         save_every=1000,\n",
    "         save_gdrive=False,\n",
    "         learning_rate=1e-4,\n",
    "         batch_size=1, \n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aitransfer",
   "language": "python",
   "name": "aitransfer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
